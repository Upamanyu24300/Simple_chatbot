{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b004f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Chatbot\n",
    "\n",
    "This chatbot can keep context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "276b8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792ab553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F5481CF0D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F5482095A0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c72f138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Upamanyu!\\n\\nThat's great to know! MTech in Computer Science Engineering is a fascinating field.  \\n\\nWhat area of CSE are you specializing in? Are you working on any interesting projects right now?\\n\\nI'm happy to chat with you about anything related to technology, academics, or even just general interests.  Let me know what's on your mind!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 26, 'total_tokens': 108, 'completion_time': 0.149090909, 'prompt_time': 0.002095529, 'queue_time': 0.26487378, 'total_time': 0.151186438}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--563fdf00-4d3f-4588-a28a-16384e854570-0', usage_metadata={'input_tokens': 26, 'output_tokens': 82, 'total_tokens': 108})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Upamanyu and I'm an MTech CSE student\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e997efa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I don't have memory of past conversations. \\n\\nYou introduced yourself as **Upamanyu**, an **MTech CSE student**. 😊 \\n\\n\\nLet me know if you have any other questions.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 117, 'total_tokens': 167, 'completion_time': 0.090909091, 'prompt_time': 0.00565026, 'queue_time': 0.25818028, 'total_time': 0.096559351}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--a66520e2-53d8-49b5-a3ff-9e17c829d325-0', usage_metadata={'input_tokens': 117, 'output_tokens': 50, 'total_tokens': 167})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, My name is Upamanyu and I'm an MTech CSE student\"),\n",
    "    AIMessage(content=\"Hello Upamanyu!\\n\\nIt's nice to meet you. That's great! MTech in Computer Science and Engineering is a challenging and rewarding field. What area of CSE are you specializing in?\\n\\nI'm happy to chat with you about anything related to technology, programming, or your studies if you'd like.\\n\"),\n",
    "    HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1fe81e",
   "metadata": {},
   "source": [
    "### Message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ba8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537c123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c38503b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Upamanyu and I'm an MTech CSE student\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "064e8180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Upamanyu,\\n\\nIt's nice to meet you!\\n\\nBeing an MTech CSE student is exciting. What area of computer science are you specializing in?  Do you have any specific projects or interests you're working on?\\n\\nI'm happy to chat about anything related to computer science, or just general topics if you'd like.  😊\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc797551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Upamanyu.  \\n\\nYou told me at the beginning of our conversation! 😊  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 118, 'total_tokens': 142, 'completion_time': 0.043636364, 'prompt_time': 0.00570955, 'queue_time': 0.263926508, 'total_time': 0.049345914}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d9980591-bea8-4930-b4bd-92ea76549570-0', usage_metadata={'input_tokens': 118, 'output_tokens': 24, 'total_tokens': 142})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86799556",
   "metadata": {},
   "source": [
    "#### Changing the config and seesion id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99c4ae5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to use it!\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4851c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi George! It's nice to meet you. What can I do for you today? 😊  \\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey my name is George\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8396b84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is George, that's what you told me!  \\n\\nIs there anything else I can help you with, George?\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22283bd",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dac7040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer the questions to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6fba0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Upamanyu, it's nice to meet you!\\n\\nWhat can I do for you today? 😊 \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 32, 'total_tokens': 60, 'completion_time': 0.050909091, 'prompt_time': 0.003313179, 'queue_time': 0.454246029, 'total_time': 0.05422227}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--0d33d12c-c9f6-4ebb-b477-26814c6a4ea3-0', usage_metadata={'input_tokens': 32, 'output_tokens': 28, 'total_tokens': 60})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"Hi, My name is Upamanyu\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa7f3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history=get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa23b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Upamanyu! It's nice to meet you.\\n\\nWhat can I do for you today? 😊  \\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Upamanyu\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751c6a62",
   "metadata": {},
   "source": [
    "#### Adding more complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3ed001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer the questions to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67f3b7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'নমস্কার, Upamanyu! 😊  আমি তোমার সাহায্যকারী।  কী প্রশ্ন তুমি জানতে চাও?  আমি যা জানি তা সব শেয়ার করবো। \\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, My name is Upamanyu\")], \n",
    "    \"language\": \"Bengali\"\n",
    "    })\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d41e0e",
   "metadata": {},
   "source": [
    "Let's now wrap this more complicated chain in a Message History class. This time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ddce329",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "294d8ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'নমস্কার, Upamanyu!  😊 \\n\\nআপনি কিভাবে আছেন? আমি আপনার সাহায্যে তোমাকে সর্বোত্তম ভাবে সাহায্য করার জন্য প্রস্তুত।  \\n\\nআপনি কোন প্রশ্ন করতে চান?\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\" : [HumanMessage(content=\"Hi, I'm Upamanyu\"),],\n",
    "        \"language\" : \"Bengali\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d09e8eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'আপনার নাম Upamanyu. 😊  \\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\" : [HumanMessage(content=\"What's my name?\"),],\n",
    "        \"language\" : \"Bengali\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea430a89",
   "metadata": {},
   "source": [
    "### Manage the Conversation history\n",
    "\n",
    "'trim_messages' helper to resuce how many messages we're sending to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "420ec786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=50,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\")\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9988d469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I don't have access to your personal information like your favorite ice cream flavor.  \\n\\nWhat's *your* favorite ice cream? 😊\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What ice cream do I like?\")],\n",
    "    \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f854b269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked me \"what\\'s 2 + 2\". 😊  \\n\\n\\n\\nLet me know if you want to try another one! \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What math problem did I ask for?\")],\n",
    "    \"language\": \"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e9a37b",
   "metadata": {},
   "source": [
    "### Lat's wrap this in the message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19cd0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config={\"configurable\": {\"session_id\": \"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b78b983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You haven't told me your name!  What would you like me to call you? 😊  \\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What's my name?\")],\n",
    "        \"language\": \"English\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68cac8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
